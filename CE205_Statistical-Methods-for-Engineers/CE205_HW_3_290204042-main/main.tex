\documentclass[12pt]{article}
\input{confugiration.tex}
\fancyhead[L]{CE 205 Statistical Methods for Engineers, Fall 2023, Homework-3 }
\title{\vspace{-1cm}CE 205 - HW3}
\author{Muhammet Yağcıoğlu - 290204042}
\usepackage{hyperref} 

\begin{document}
\maketitle\thispagestyle{fancy}
\pagestyle{fancy}
\tableofcontents
\newpage
\section*{Question 1}
\addcontentsline{toc}{section}{Question 1}
\begin{q}
Q1) (10p) In a clinical study, volunteers are tested for a gene that has been found to increase the risk for a disease. The probability that a person carries the gene is 0.1.
(a) What is the probability 4 or more people will have to be tested before 2 with the gene are detected?
(b) How many people are expected to be tested before 2 with the gene are detected?
\end{q}

Let \( X \) be a discrete random variable, the number of trials needed to achieve two successes, where each trial is an independent Bernoulli trial with success probability \( p = 0.1 \). As the distribution of the number of Bernoulli trials required to achieve a fixed number of successes, the random variable \( X \) follows a negative binomial distribution. The negative binomial distribution, \( \text{NB}(r, p) \), is parameterized by \( r \) (the number of successes to be achieved) and \( p \) (the probability of success in each trial). For \( X \sim \text{NB}(r, p) \), the probability mass function is given by
\[ \mathrm{P}(X = x) = \binom{x-1}{r-1} p^r (1-p)^{x-r}, \, \text{for} \, x \geq r, x \in \mathbb{N}. \]

\subsection*{Part a}

To calculate \( \mathrm{P}(X \geq 4) \), consider the complement event, \( \mathrm{P}(X < 4) \), which encompasses the scenarios where 2 successes are achieved in either 2 or 3 trials. The explicit is sum of probabilities for \( X = 2 \) and \( X = 3 \):\[ \mathrm{P}(X < 4) = \mathrm{P}(X = 2) + \mathrm{P}(X = 3). \]For \( X = 2 \),\( \mathrm{P}(X = 2) = \binom{1}{1} (0.1)^2 (0.9)^{0} = 0.01. \) For \( X = 3 \),\( \mathrm{P}(X = 3) = \binom{2}{1} (0.1)^2 (0.9)^{1} = 0.018. \) Thus, \[ \mathrm{P}(X \geq 4) = 1 - \mathrm{P}(X < 4) = 1 - [0.01 + 0.018] = 0.972. \]
\AnswerTag
\subsection*{Part b}

The expectation \( E[X] \) is defined as \[ E[X] = \sum_{x=r}^{\infty} x \cdot \mathrm{P}(X = x). \] Substituting the probability mass function, we get \[ E[X] = \sum_{x=r}^{\infty} x \binom{x-1}{r-1} p^r (1-p)^{x-r}. \] \[ \binom{x-1}{r-1} = \frac{(x-1)!}{(r-1)!(x-r)!} = \frac{x}{r} \cdot \frac{(x-1)!}{(r-1)!((x-1)-(r-1))!} = \frac{x}{r} \binom{x-1}{r}. \] Thus, \[ E[X] = \sum_{x=r}^{\infty} \frac{x}{r} \binom{x-1}{r} p^r (1-p)^{x-r}. \] Now, notice that \( \frac{x}{r} \binom{x-1}{r} \) is the number of ways to choose \( r \) successes in \( x-1 \) trials and then have a success on the \( x \)-th trial. Hence, this is equivalent to finding the expected number of trials to achieve the \( r \)-th success.  By the linearity of expectation, we can consider each success separately. The expected number of trials to achieve the first success is \( \frac{1}{p} \), by the geometric distribution's mean. Similarly, the expected number of additional trials to achieve the second success is also \( \frac{1}{p} \), and so on, up to the \( r \)-th success. Therefore, the total expected number of trials to achieve \( r \) successes is \[ E[X] = \frac{1}{p} + \frac{1}{p} + \cdots + \frac{1}{p} = \frac{r}{p}. \] For our case with \( r = 2 \) and \( p = 0.1 \), this yields \[ E[X] = \frac{2}{0.1} = 20. \] This means that, on average, 20 people have to be checked before two people having the gene are found.
\AnswerTag

\vfill
\begin{flushright}
\textbf{ans.} \(  \mathrm{P}(X \geq 4) = 0.972, E[X] = 20.\)
\end{flushright}


\newpage
\section*{Question 2}
\addcontentsline{toc}{section}{Question 2}
\begin{q}
Q2) (10p) Assume that each of your calls to a popular radio station has a probability of 0.02 of connecting, that is, of not obtaining a busy signal. Assume that your calls are independent.
(a) What is the probability that your first call that connects is your tenth call?
(b) What is the probability that it requires more than five calls for you to connect?
(c) What is the mean number of calls needed to connect?
\end{q}


Let \( X \) the number of calls needed to successfully connect to the radio station. Given that each call is an independent Bernoulli trial with success probability \( p = 0.02 \), it follows that \( X \) is a geometric random variable. The probability mass function of a geometric distribution for a discrete random variable \( X \), the number of trials until the first success is

\[ \mathrm{P}(X = k) = (1 - p)^{k-1} p, \, \text{for} \, k \in \{1, 2, 3, \ldots\}\]

\subsection*{Part a}

\[ \mathrm{P}(X = 10) = (1 - 0.02)^9 \times 0.02 = 0.98^9 \times 0.02 = 0.0167. \]
\AnswerTag
\subsection*{Part b}

The probability that more than five calls are needed to connect, denoted as \( \mathrm{P}(X > 5) \), is the complement of the probability that a connection is made in five or fewer calls. Using the cumulative distribution function of the geometric distribution: \[ \mathrm{P}(X > 5) = 1 - \mathrm{P}(X \leq 5) = 1 - \sum_{k=1}^{5} \mathrm{P}(X = k), \] \[ \mathrm{P}(X > 5) = 1 - [0.02 + 0.98 \times 0.02 + 0.98^2 \times 0.02 + 0.98^3 \times 0.02 + 0.98^4 \times 0.02] = 0.9039. \] Alternatively, recognizing that \( \mathrm{P}(X > 5) \) is the probability of no successes in the first five trials, we have: \[ \mathrm{P}(X > 5) = 0.98^5 = 0.9039. \]
\AnswerTag
\subsection*{Part c}

\[ E[X] = \sum_{k=1}^{\infty} k \cdot \mathrm{P}(X = k) = \sum_{k=1}^{\infty} k (1 - p)^{k-1} p, \] \[ f(x) = \sum_{k=1}^{\infty} x^k = x + x^2 + x^3 + \cdots, = \frac{x}{1 - x} \text{ for } |x| < 1 ,\] \[ f'(x) = \frac{d}{dx}\left(\frac{x}{1 - x}\right) = \frac{1}{(1 - x)^2}. \] However, \[ f'(x) = \frac{d}{dx}\left( \sum_{k=1}^{\infty} x^k \right) = \sum_{k=1}^{\infty} k x^{k-1}. \] Setting \( x = 1 - p \) and multiplying by \( p \) (as in our original expectation formula), we obtain \[ E[X] = p \cdot \frac{1}{p^2} = \frac{1}{p}. \] So, the mean, or expected value, of a geometrically distributed random variable \( X \) is given by \( \frac{1}{p} \). For our scenario: \[ E[X] = \frac{1}{0.02} = 50. \]
\AnswerTag


\vfill
\begin{flushright}
\textbf{ans.} \( \mathrm{P}(X = 10) = 0.0167, \mathrm{P}(X > 5) = 0.9039,  E[X] = 50.\)
\end{flushright}

\newpage
\section*{Question 3}
\addcontentsline{toc}{section}{Question 3}
\begin{q}
Q3) (10p) The time to failure (in hours) fans in a personal computer can be modeled by an exponential distribution with \(\lambda=0.0003\).
(a) What proportion of the fans will last at least 10,000 hours?
(b) What proportion of the fans will last at most 7000 hours?
\end{q}


Let \( X \) the time to failure (in hours) of fans in a personal computer. Given that \( X \) is an exponential random variable, it follows that the probability density function of \( X \) is given by \[ f(x; \lambda) = \lambda e^{-\lambda x}, \] for \( x \geq 0 \), where \( \lambda = 0.0003 \) is the rate parameter of the distribution.

\subsection*{Part a}

To find the proportion of fans that will last at least 10,000 hours, we calculate \( \mathrm{P}(X > 10,000) \). This is the tail probability of the exponential distribution, \[ \mathrm{P}(X > 10,000) = \int_{10,000}^{\infty} 0.0003 e^{-0.0003 x} dx. \]\[ \mathrm{P}(X > 10,000) = -\left.e^{-0.0003 x}\right|_{10,000}^{\infty}. \] \[ \mathrm{P}(X > 10,000) = e^{-3} \approx 0.0498. \]
\AnswerTag

\subsection*{Part b}

To determine the proportion of fans that will last at most 7,000 hours, we compute \( \mathrm{P}(X < 7,000) \). \[ \mathrm{P}(X < 7,000) = \int_{0}^{7,000} 0.0003 e^{-0.0003 x} dx. \] \[ \mathrm{P}(X < 7,000) = -\left.e^{-0.0003 x}\right|_{0}^{7,000}. \] \[ \mathrm{P}(X < 7,000) = 1 - e^{-2.1} \approx 0.8775. \]

\AnswerTag


\vfill
\begin{flushright}
\textbf{ans.} \(\mathrm{P}(X > 10,000) \approx 0.0498, \mathrm{P}(X < 7,000) \approx 0.8775.\)
\end{flushright}



\newpage
\section*{Question 4}
\addcontentsline{toc}{section}{Question 4}

\begin{q}
Q4) (20p) The joint probability distribution is
\[
\begin{array}{lccll}
 x & -1 & 0 & 0 & 1 \\
\hline y & 0 & -1 & 1 & 0 \\
\hline f_{X Y}(x, y) & 1 / 4 & 1 / 4 & 1 / 4 & 1 / 4

\end{array}
\]

Show that the correlation between \(X\) and \(Y\) is zero, but \(X\) and \(Y\) are not independent.
\end{q}


Let \( X \) and \( Y \) be discrete random variables with a given joint probability distribution \( f_{XY}(x, y) \). 

Given \( f_{XY}(x, y) \):

\[
\begin{array}{c|ccc}
 & X=-1 & X=0 & X=1 \\
\hline Y=0 & \frac{1}{4} & \frac{1}{4} & \frac{1}{4} \\
Y=-1 & 0 & \frac{1}{4} & 0 \\
Y=1 & 0 & \frac{1}{4} & 0 \\
\end{array}
\]

First, we compute the expectations \( E[X] \) and \( E[Y] \). By definition,
\[ E[X] = \sum_{x} x \cdot P_X(x) = \sum_{x} x \cdot \sum_{y} f_{XY}(x, y), \]
and similarly for \( E[Y] \). Calculating these sums, we find:
\[ E[X] = -1 \cdot \frac{1}{4} + 0 \cdot \frac{1}{4} + 1 \cdot \frac{1}{4} = 0, \]
\[ E[Y] = 0 \cdot \frac{3}{4} - 1 \cdot \frac{1}{4} + 1 \cdot \frac{1}{4} = 0. \]

Next, calculate the expectation \( E[XY] \):
\[ E[XY] = \sum_{x} \sum_{y} xy \cdot f_{XY}(x, y) = [-1 \times 0 \times(1 / 4)]+[-1 \times 0 \times(1 / 4)]+[1 \times 0 \times(1 / 4)]+[0 \times 1 \times(1 / 4)]=0. \]
The variances \( V[X] \) and \( V[Y] \) are
\[ V[X] = E[X^2] - (E[X])^2, \]
\[ V[Y] = E[Y^2] - (E[Y])^2. \]
Performing the calculations reveals \( V[X] = \frac{1}{2} \) and \( V[Y] = \frac{1}{2} \).

The covariance \( \sigma_{XY} \) is defined as \( E[XY] - E[X]E[Y] \). Here, it simplifies to:
\[ \sigma_{XY} = 0 - (0)(0) = 0. \]

Thus, the correlation coefficient \( \rho_{XY} \), given by \( \frac{\sigma_{XY}}{\sqrt{V[X]V[Y]}} \), is computed as:
\[ \rho_{XY} = \frac{0}{\sqrt{\frac{1}{2} \cdot \frac{1}{2}}} = 0. \]

The zero correlation implies no linear relationship between \( X \) and \( Y \). However, independence is not guaranteed by zero correlation. Two variables are independent if and only if their joint distribution is the product of their marginal distributions. Examining \( f_{XY}(x, y) \), we note that the product of the marginals does not equal the joint distribution in all cases, indicating that \( X \) and \( Y \) are not independent.







\newpage
\section*{Question 5}
\addcontentsline{toc}{section}{Question 5}

\begin{q}
Q5) (20p) A random variable \(X\) has the following probability distribution:
\[
f_X(x)=e^{-x}, \quad x \geq 0
\]
(a) Find the probability distribution for \(Y=X^2\)
(b) Find the probability distribution for \(Y=X^{0.5}\)
(c) Find the probability distribution for \(Y=\ln X\)
\end{q}


\subsection*{Part a}
For the transformation \( Y = X^2 \), the inverse transformation is \( X = \sqrt{Y} \). The domain of \( Y \) is \( y \geq 0 \). The probability density function \( f_Y(y) \) is obtained by taking the derivative of the transformation with respect to \( y \) and substituting into \( f_X(x) \). Specifically, 
\[ f_Y(y) = f_X(\sqrt{y}) \left| \frac{d}{dy}\sqrt{y} \right| = f_X(\sqrt{y}) \cdot \frac{1}{2} y^{-\frac{1}{2}} =  f_Y(y) = \frac{e^{-\sqrt{y}}}{2 \sqrt{y}}, \,  y > 0.\]

\subsection*{Part b}

\[ f_Y(y) = f_X(y^2) \left| \frac{d}{dy}y^2 \right| = f_X(y^2) \cdot 2y  2y e^{-y^2}, \,  y > 0 . \]

\subsection*{Part c}

\[ f_Y(y) = f_X(e^y) \left| \frac{d}{dy}e^y \right| = f_X(e^y) \cdot e^y e^y e^{-e^y} = e^{y - e^y}, \, y\in \mathbb{R}. \]



\vfill
\begin{flushright}
\textbf{ans.} \(f_{X^2 \rightarrow Y} = \frac{e^{-\sqrt{y}}}{2 \sqrt{y}}, \,  y > 0, f_{X^{0.5}\rightarrow Y}=\frac{e^{-\sqrt{y}}}{2 \sqrt{y}}, \,  y > 0, f_{\ln{X} \rightarrow Y}=e^{y - e^y}, \, y\in \mathbb{R}.\)
\end{flushright}




\newpage
\section*{Question 6}
\addcontentsline{toc}{section}{Question 6}

\begin{q}
Q6) (30p) In the manufacture of electroluminescent lamps, several different layers of ink are deposited onto a plastic substrate. The thickness of these layers is critical if specifications regarding the final color and intensity of light of the lamp are to be met. Let \(X\) and \(Y\) denote the thickness of two different layers of ink. It is known that \(X\) is normally distributed with a mean of 0.1 millimeter and a standard deviation of 0.00031 millimeter and \(Y\) is also normally distributed with a mean of 0.23 millimeter and a standard deviation of 0.00017 millimeter. Assume that these variables are independent.
(a) If a particular lamp is made up of these two inks only, what is the probability that the total ink thickness is less than 0.2337 millimeter?

(b) A lamp with a total ink thickness exceeding 0.2405 millimeters lacks the uniformity of color demanded by the customer. Find the probability that a randomly selected lamp fails to meet customer specifications.
\end{q}


\subsection*{Part a}

Given \( X \sim \mathrm{N}(0.1, 0.00031^2) \) and \( Y \sim \mathrm{N}(0.23, 0.00017^2) \), let \( T = X + Y \) denote the total thickness. Since \( X \) and \( Y \) are independent normal random variables, their sum \( T \) is also normally distributed. The mean and variance of \( T \) are given by the sums of the means and variances of \( X \) and \( Y \), respectively.

\[ E[T] = E[X] + E[Y] = 0.1 + 0.23 = 0.33 \, \text{mm}. \]
\[ V[T] = V[X] + V[Y] = 0.00031^2 + 0.00017^2 = 1.25 \times 10^{-7} \, \text{mm}^2. \]
\[ \sigma_T = \sqrt{V[T]} = \sqrt{1.25 \times 10^{-7}} \approx 0.000354 \, \text{mm}. \]
\[ P(T < 0.2337) = P\left(Z < \frac{0.2337 - 0.33}{0.000354}\right) = P(Z < -272) = 5.557\times 10^{-16069} \cong 0.\]

\AnswerTag

\subsection*{Part b}
\[ P(T > 0.2405) = P\left(Z > \frac{0.2405 - 0.33}{0.000354}\right) = P(Z > -253) = 1-6.607 \times 10^{-13903} \cong 1.\]
\AnswerTag

\vfill
\begin{flushright}
\textbf{ans.} \(P(T < 0.2337)\cong 0, P(T > 0.2405) \cong 1.\)
\end{flushright}
\end{document}